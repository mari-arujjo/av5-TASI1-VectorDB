# üìå Sistema de Recupera√ß√£o de Informa√ß√µes usando VectorDB e RetrievalQA
Esse reposit√≥rio √© referente a AV5 da mat√©ria de TASI 1, contendo um script Python que utiliza embenddings e um VectorDB para responder perguntas. Esse sitema integra a biblioteca LangChain e o m√≥dulo RetrivalQA.
- Lembrar de retirar as aspas simples '' na execu√ß√£o dos codigos no terminal.

## üò≠ Observa√ß√£o importante!
Professor, eu simplesmente n√£o consegui executar meu c√≥digo pois meu PC n√£o tem mem√≥ria RAM suficiente pra isso, aparece essa mensagem:
ollama._types.ResponseError: model requires more system memory (5.6 GiB) than is available (4.3 GiB) (status code: 500)
Eu testei 4 modelos diferentes (llama3, mistral, nomic/mini e phi3:mini) mas meu PC n√£o tanka nenhum deles, ent√£o n√£o tenho nenhum v√≠deo de demonstra√ß√£o e n√£o sei quais erros tem na execu√ß√£o do script... Mas como eu tive muita dificuldade em fazer essa atividade e ralei muito, estou entregando aqui!
Espero que entenda D=


## üîß Pr√©-requisitos!
- Ollama instalado (https://ollama.com/download)
- Ter o modelo LLM "phi3:mini" instalado na m√°quina (rode no terminal 'ollama pull phi3:mini').
- Modelo 'nomic-embed-text' baixado (rode no terminal 'ollama pull nomic-embed-text').
- Bibliotecas do langchain, faiss e pypdf baixados (rode no terminal 'pip install langchain langchain-community langchain-ollama faiss-cpu pypdf').
- Python 3 + pip.


## üöÄ Como executar?
1. Quando instalamos o Ollama ele come√ßa a rodar em segundo plano automaticamente, para verificar execute no seu terminal 'ollama list', deve aparecer informa√ß√µes como o nome do modelo, a mem√≥ria utilizada e a √∫ltima modifica√ß√£o feita. Caso n√£o apare√ßa nenhuma dessas informa√ß√µes, inicie o Ollama executando no seu terminal 'ollama serve'.
Baixe o arquivo 'av3_script.py'.
2. Baixe o arquivo 'av5_script.py'.
3. Abra no terminal o diret√≥rio onde o arquivo .py est√° localizado: 'cd C:/Users/seu_user/.........'.
4. Execute o arquivo .py no terminal: 'python av5_script.py'.